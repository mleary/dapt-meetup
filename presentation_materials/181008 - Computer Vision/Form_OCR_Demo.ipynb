{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from http import client\n",
    "from urllib import request, parse, error\n",
    "import base64\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import glob\n",
    "\n",
    "#os.chdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 / Parse PDF and convert to image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most PDFs that you work with will be multiple pages. You will want to parse these pdfs into their individual pages and convert to images. Luckily, images can't be multiple pages so most tools will both steps at the same time!\n",
    "I am using XpdfReader's command utility pdftopng. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.call(\"pdftopng -q -r 300 Demo_Acord.pdf Demo_Acord\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reminder : Show the Image form that we are parsing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 / Image Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This is super important but not relevant our sample form\n",
    "For image classification, you may want to explore \n",
    "* resizing\n",
    "* normalizing values\n",
    "* dimensionality reduction.\n",
    "* etc.\n",
    "\n",
    "For OCR, the goal of preprocessing is to make text more clear. You may want to:\n",
    "* Scale to a larger size\n",
    "* Increase contrast\n",
    "* Deskew (remove rotation)\n",
    "* etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 / OCR Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am using Microsoft Azure's OCR engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Micro_Vision(key = None, image_path = None):\n",
    "    \n",
    "    subscription_key = key\n",
    "    assert subscription_key\n",
    "    \n",
    "    image_path = image_path\n",
    "    \n",
    "    ocr_url = \"https://eastus.api.cognitive.microsoft.com/vision/v2.0/ocr\"\n",
    "    \n",
    "    with open(image_path, 'rb') as f:\n",
    "        image = f.read()\n",
    "    \n",
    "    headers = {'Ocp-Apim-Subscription-Key': subscription_key,\n",
    "               'Content-Type' : 'application/octet-stream'}\n",
    "    \n",
    "    params  = {'language': 'en', \n",
    "               'detectOrientation': 'true'}\n",
    "    \n",
    "    response = requests.post(ocr_url, headers=headers, params=params, data=image)\n",
    "    \n",
    "    return(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"Demo_Acord-000001.png\"\n",
    "response = Micro_Vision(image_path = image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 / Identify Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(ocr_results):\n",
    "    line_infos = [region[\"lines\"] for region in ocr_results[\"regions\"]]\n",
    "    word_infos = []\n",
    "    for line in line_infos:\n",
    "        for word_metadata in line:\n",
    "            for word_info in word_metadata[\"words\"]:\n",
    "                word_infos.append(word_info)\n",
    "    return(word_infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_infos = get_words(ocr_results = response)\n",
    "word_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30, 30))\n",
    "image = Image.open(image_path)\n",
    "ax = plt.imshow(image, alpha=0.5)\n",
    "for word in word_infos:\n",
    "    bbox = [int(num) for num in word[\"boundingBox\"].split(\",\")]\n",
    "    text = word[\"text\"]\n",
    "    origin = (bbox[0], bbox[1])\n",
    "    patch  = Rectangle(origin, bbox[2], bbox[3], fill=False, linewidth=2, color='y')\n",
    "    ax.axes.add_patch(patch)\n",
    "    plt.text(origin[0], origin[1], text, fontsize=20, weight=\"bold\", va=\"top\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looks pretty good for the most part, but how do we ensure that we're going to get all of the values we are looking for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zonal (or Template) OCR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to build a template. To do this we need to understand that an image is like a map in the sense that the location (or index) of pixels is meaningful. So we need to find the x and y as well as width and height of text that we'd like to extract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = pd.read_csv(\"bounding_boxes.csv\")\n",
    "bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View cropped image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_name = \"Lim_Med\"\n",
    "x, y, w, h = bounds[bounds['Field_Name'] == field_name].iloc[0,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "img = cv2.imread(image_path)\n",
    "crop_image = img[y:y+h, x:x+w]\n",
    "plt.imshow(crop_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse each box and write to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_form(image_path, bounds):\n",
    "    img = cv2.imread(image_path)\n",
    "    bounds = pd.read_csv(bounds)\n",
    "    for i in range(len(bounds)):\n",
    "        x, y, w, h = bounds.iloc[i,1:]\n",
    "        crop_image = img[y:y+h, x:x+w]\n",
    "        cv2.imwrite(\"form_parts/\" + bounds.iloc[i,0] + \".png\", crop_image)\n",
    "    \n",
    "    if len(glob.glob('form_parts/*.png')) == len(bounds):\n",
    "        print('Successfully parsed image!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_form(image_path = image_path, bounds = \"bounding_boxes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forms = glob.glob('form_parts/*.png')\n",
    "forms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run OCR on each bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def part_ocr(field_name = None):\n",
    "    find_me = [x.find('Agency') for x in forms]\n",
    "    im_found = find_me.index(max(find_me))\n",
    "    ocr_part = Micro_Vision(image_path = forms[im_found])\n",
    "    return(ocr_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_json = part_ocr(field_name = 'Agency')\n",
    "part_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_words(part_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for form_part in forms:\n",
    "    result = Micro_Vision(image_path = form_part)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_words = [get_words(x) for x in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
